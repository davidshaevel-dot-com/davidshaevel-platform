# ==============================================================================
# Observability Module - Main Configuration
# ==============================================================================
#
# This module provisions infrastructure for the observability stack:
# - S3 bucket for Prometheus configuration storage
# - EFS file system for Prometheus TSDB data persistence
# - EFS mount targets for high availability across multiple AZs
# - Security groups for EFS NFS access
# - IAM policies for S3 and EFS access from ECS tasks
#
# Phase 3 of TT-25: EFS file systems and supporting infrastructure
#
# Architecture:
# 1. Prometheus config rendered by Terraform → S3 bucket
# 2. ECS init container syncs S3 → EFS (one-time per task start)
# 3. Prometheus container reads config from EFS, writes data to EFS
# 4. EFS provides persistent storage across task restarts

locals {
  name_prefix        = "${var.environment}-${var.project_name}"
  prometheus_port    = 9090
  grafana_port       = 3000
  nfs_port           = 2049    # Standard NFS/EFS mount port
  prometheus_user_id = "65534" # UID for 'nobody' user - standard Prometheus non-root user
  grafana_user_id    = "472"   # UID for 'grafana' user

  common_tags = merge(
    var.tags,
    {
      Module      = "observability"
      Environment = var.environment
      Project     = var.project_name
      ManagedBy   = "Terraform"
    }
  )
}

# ==============================================================================
# S3 Bucket for Prometheus Configuration
# ==============================================================================

# S3 bucket to store rendered Prometheus configuration files
# Config is generated by Terraform from prometheus.yml.tpl template
# and synced to EFS by init container on task startup
resource "aws_s3_bucket" "prometheus_config" {
  bucket = "${local.name_prefix}-prometheus-config"

  tags = merge(
    local.common_tags,
    {
      Name    = "${local.name_prefix}-prometheus-config"
      Purpose = "Prometheus configuration storage"
    }
  )
}

# Enable versioning to track config changes over time
resource "aws_s3_bucket_versioning" "prometheus_config" {
  count  = var.enable_config_bucket_versioning ? 1 : 0
  bucket = aws_s3_bucket.prometheus_config.id

  versioning_configuration {
    status = "Enabled"
  }
}

# Enable encryption at rest with AWS-managed keys
resource "aws_s3_bucket_server_side_encryption_configuration" "prometheus_config" {
  bucket = aws_s3_bucket.prometheus_config.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# Block all public access to config bucket
resource "aws_s3_bucket_public_access_block" "prometheus_config" {
  bucket = aws_s3_bucket.prometheus_config.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# Lifecycle policy to expire old config versions
resource "aws_s3_bucket_lifecycle_configuration" "prometheus_config" {
  count  = var.config_bucket_lifecycle_days > 0 ? 1 : 0
  bucket = aws_s3_bucket.prometheus_config.id

  rule {
    id     = "expire-old-versions"
    status = "Enabled"

    noncurrent_version_expiration {
      noncurrent_days = var.config_bucket_lifecycle_days
    }
  }
}

# ==============================================================================
# EFS File System for Prometheus Data
# ==============================================================================

# EFS file system for Prometheus TSDB data persistence
# Stores metrics data across ECS task restarts
# Multi-AZ for high availability
resource "aws_efs_file_system" "prometheus" {
  count = var.enable_prometheus_efs ? 1 : 0

  # Performance configuration
  performance_mode = var.prometheus_efs_performance_mode
  throughput_mode  = var.prometheus_efs_throughput_mode

  # Encryption at rest with AWS-managed KMS key
  encrypted = var.enable_efs_encryption

  # EFS Lifecycle policies:
  # 1. Transition files to Infrequent Access (IA) storage after a configured
  #    number of days (`var.efs_transition_to_ia_days`) to reduce storage costs.
  # 2. Transition files back to Standard storage from IA on the first access
  #    to ensure performance for active data.
  lifecycle_policy {
    transition_to_ia = "AFTER_${var.efs_transition_to_ia_days}_DAYS"
  }

  lifecycle_policy {
    transition_to_primary_storage_class = "AFTER_1_ACCESS"
  }

  tags = merge(
    local.common_tags,
    {
      Name    = "${local.name_prefix}-prometheus-data"
      Purpose = "Prometheus TSDB data persistence"
    }
  )
}

# EFS File System for Grafana Data (Phase 10)
# Stores Grafana internal database (sqlite3), plugins, and image rendering artifacts
# Persistent storage is critical to retain users, dashboards, and alert rules across restarts
resource "aws_efs_file_system" "grafana" {
  count = var.enable_grafana ? 1 : 0

  # Encryption at rest with AWS-managed KMS key
  encrypted = var.enable_efs_encryption

  # EFS Lifecycle policies to optimize storage costs
  # Grafana data is accessed frequently, but old logs/artifacts might be cold
  lifecycle_policy {
    transition_to_ia = "AFTER_30_DAYS"
  }

  lifecycle_policy {
    transition_to_primary_storage_class = "AFTER_1_ACCESS"
  }

  tags = merge(
    local.common_tags,
    {
      Name    = "${local.name_prefix}-grafana-data"
      Purpose = "Grafana persistent storage"
    }
  )
}

# ==============================================================================
# EFS Mount Targets
# ==============================================================================

# Create EFS mount target in each private app subnet for multi-AZ availability
# Allows ECS tasks in any AZ to access the file system
resource "aws_efs_mount_target" "prometheus" {
  count = var.enable_prometheus_efs ? length(var.private_app_subnet_ids) : 0

  file_system_id  = aws_efs_file_system.prometheus[0].id
  subnet_id       = var.private_app_subnet_ids[count.index]
  security_groups = [aws_security_group.efs[0].id]
}

# Grafana Mount Targets
resource "aws_efs_mount_target" "grafana" {
  count = var.enable_grafana ? length(var.private_app_subnet_ids) : 0

  file_system_id  = aws_efs_file_system.grafana[0].id
  subnet_id       = var.private_app_subnet_ids[count.index]
  security_groups = [aws_security_group.efs[0].id]
}

# ==============================================================================
# EFS Security Group
# ==============================================================================

# Security group for EFS mount targets
# Allows NFS traffic (port 2049) from Prometheus ECS tasks
resource "aws_security_group" "efs" {
  count = var.enable_prometheus_efs ? 1 : 0

  name_prefix = "${local.name_prefix}-efs-"
  description = "Security group for Prometheus EFS mount targets"
  vpc_id      = var.vpc_id

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-efs-sg"
    }
  )

  lifecycle {
    create_before_destroy = true
  }
}

# Ingress rule: Allow NFS (port 2049) from Prometheus security group
# Security groups are stateful - this ingress rule automatically allows return traffic
# No explicit egress rule needed for EFS mount targets (passive endpoints)
resource "aws_vpc_security_group_ingress_rule" "efs_nfs_from_prometheus" {
  count = var.enable_prometheus_efs ? 1 : 0

  security_group_id            = aws_security_group.efs[0].id
  description                  = "Allow NFS from Prometheus ECS tasks"
  referenced_security_group_id = var.prometheus_security_group_id
  from_port                    = local.nfs_port
  to_port                      = local.nfs_port
  ip_protocol                  = "tcp"

  tags = merge(
    local.common_tags,
    {
      Name = "efs-nfs-from-prometheus"
    }
  )
}

# Egress rule: Allow Prometheus to connect to EFS on NFS port
# Required for Fargate tasks to mount EFS volumes
resource "aws_vpc_security_group_egress_rule" "prometheus_to_efs" {
  count = var.enable_prometheus_efs ? 1 : 0

  security_group_id            = var.prometheus_security_group_id
  description                  = "Allow NFS to EFS mount targets"
  referenced_security_group_id = aws_security_group.efs[0].id
  from_port                    = local.nfs_port
  to_port                      = local.nfs_port
  ip_protocol                  = "tcp"

  tags = merge(
    local.common_tags,
    {
      Name = "prometheus-to-efs-nfs"
    }
  )
}

# ==============================================================================
# Grafana Security Group
# ==============================================================================

# Security group for Grafana ECS tasks
# Controls network access to/from Grafana containers
resource "aws_security_group" "grafana" {
  count = var.enable_grafana && var.grafana_security_group_id == "" ? 1 : 0

  name_prefix = "${local.name_prefix}-grafana-"
  description = "Security group for Grafana ECS tasks"
  vpc_id      = var.vpc_id

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-grafana-sg"
    }
  )

  lifecycle {
    create_before_destroy = true
  }
}

locals {
  grafana_sg_id = var.enable_grafana ? (var.grafana_security_group_id != "" ? var.grafana_security_group_id : aws_security_group.grafana[0].id) : ""
}

# Allow Grafana to access EFS on NFS port (2049)
# Required for mounting the persistent storage volume
resource "aws_vpc_security_group_ingress_rule" "efs_nfs_from_grafana" {
  count = var.enable_grafana ? 1 : 0

  security_group_id            = aws_security_group.efs[0].id
  description                  = "Allow NFS from Grafana ECS tasks"
  referenced_security_group_id = local.grafana_sg_id
  from_port                    = local.nfs_port
  to_port                      = local.nfs_port
  ip_protocol                  = "tcp"
}

resource "aws_vpc_security_group_egress_rule" "grafana_to_efs" {
  count = var.enable_grafana ? 1 : 0

  security_group_id            = local.grafana_sg_id
  description                  = "Allow NFS to EFS mount targets"
  referenced_security_group_id = aws_security_group.efs[0].id
  from_port                    = local.nfs_port
  to_port                      = local.nfs_port
  ip_protocol                  = "tcp"
}

# Allow Grafana to access Prometheus (port 9090)
# Grafana queries Prometheus as a datasource to visualize metrics
resource "aws_vpc_security_group_ingress_rule" "prometheus_from_grafana" {
  count = var.enable_grafana ? 1 : 0

  security_group_id            = var.prometheus_security_group_id
  description                  = "Allow Grafana to query Prometheus"
  referenced_security_group_id = local.grafana_sg_id
  from_port                    = local.prometheus_port
  to_port                      = local.prometheus_port
  ip_protocol                  = "tcp"
}

resource "aws_vpc_security_group_egress_rule" "grafana_to_prometheus" {
  count = var.enable_grafana ? 1 : 0

  security_group_id            = local.grafana_sg_id
  description                  = "Allow Grafana to query Prometheus"
  referenced_security_group_id = var.prometheus_security_group_id
  from_port                    = local.prometheus_port
  to_port                      = local.prometheus_port
  ip_protocol                  = "tcp"
}

# Allow outbound internet access for Grafana
# Needed for:
# 1. Installing plugins at runtime (if not baked into image)
# 2. Checking for version updates
# 3. Configuring external datasources (e.g. CloudWatch)
# 4. Configuring external authentication (e.g. OAuth)
# NOTE: This rule is permissive (all ports) to allow Grafana to connect to diverse datasources
# (e.g. Postgres on 5432, MySQL on 3306, external APIs on 443/80).
# Restricting this would require predicting every future integration.
resource "aws_vpc_security_group_egress_rule" "grafana_to_internet" {
  count = var.enable_grafana ? 1 : 0

  security_group_id = local.grafana_sg_id
  description       = "Allow outbound internet access"
  cidr_ipv4         = "0.0.0.0/0"
  ip_protocol       = "-1"
}

# Allow ALB to access Grafana (port 3000)
# Required for public access and health checks
resource "aws_vpc_security_group_ingress_rule" "grafana_from_alb" {
  count = var.enable_grafana && var.alb_security_group_id != null ? 1 : 0

  security_group_id            = local.grafana_sg_id
  description                  = "Allow traffic from ALB"
  referenced_security_group_id = var.alb_security_group_id
  from_port                    = local.grafana_port
  to_port                      = local.grafana_port
  ip_protocol                  = "tcp"
}

# Allow ALB outbound to Grafana (port 3000)
# Note: ALB SG is managed in networking module, but we add this rule here
# to keep Grafana-specific configuration co-located with the service
resource "aws_vpc_security_group_egress_rule" "alb_to_grafana" {
  count = var.enable_grafana && var.alb_security_group_id != null ? 1 : 0

  security_group_id            = var.alb_security_group_id
  description                  = "Allow traffic to Grafana containers"
  referenced_security_group_id = local.grafana_sg_id
  from_port                    = local.grafana_port
  to_port                      = local.grafana_port
  ip_protocol                  = "tcp"
}

# ==============================================================================
# Secrets Manager for Grafana Admin Password
# ==============================================================================

# Generate a random password if one isn't provided via variables
# This ensures secure default authentication for the admin user
resource "random_password" "grafana_admin" {
  count = var.enable_grafana ? 1 : 0

  length           = 16
  special          = true
  override_special = "!#$%&*()-_=+[]{}<>:?"
}

# Store the admin password in Secrets Manager
# ECS task definition will inject this as an environment variable (GF_SECURITY_ADMIN_PASSWORD)
resource "aws_secretsmanager_secret" "grafana_admin" {
  count = var.enable_grafana ? 1 : 0

  name_prefix = "${local.name_prefix}-grafana-admin-password-"
  description = "Grafana admin password"

  # Force deletion allows easier cleanup for dev environments
  # Use 0 (immediate) for dev to allow rapid destroy/apply cycles, 7 days for other envs safety
  recovery_window_in_days = var.environment == "dev" ? 0 : 7

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-grafana-admin-secret"
    }
  )
}

resource "aws_secretsmanager_secret_version" "grafana_admin" {
  count = var.enable_grafana ? 1 : 0

  secret_id     = aws_secretsmanager_secret.grafana_admin[0].id
  secret_string = var.grafana_admin_password != "" ? var.grafana_admin_password : random_password.grafana_admin[0].result
}

# ==============================================================================
# Security Group Rules for Metrics Scraping
# ==============================================================================

# Ingress rule: Allow Prometheus to scrape backend metrics
# Note: Egress rules for Prometheus are managed in the networking module
resource "aws_vpc_security_group_ingress_rule" "backend_from_prometheus" {
  security_group_id = var.backend_security_group_id

  description                  = "Allow Prometheus to scrape backend metrics"
  from_port                    = var.backend_metrics_port
  to_port                      = var.backend_metrics_port
  ip_protocol                  = "tcp"
  referenced_security_group_id = var.prometheus_security_group_id

  tags = merge(local.common_tags, {
    Name = "${var.environment}-${var.project_name}-backend-from-prometheus-ingress"
  })
}

# Ingress rule: Allow Prometheus to scrape frontend metrics
# Note: Egress rules for Prometheus are managed in the networking module
resource "aws_vpc_security_group_ingress_rule" "frontend_from_prometheus" {
  security_group_id = var.frontend_security_group_id

  description                  = "Allow Prometheus to scrape frontend metrics"
  from_port                    = var.frontend_metrics_port
  to_port                      = var.frontend_metrics_port
  ip_protocol                  = "tcp"
  referenced_security_group_id = var.prometheus_security_group_id

  tags = merge(local.common_tags, {
    Name = "${var.environment}-${var.project_name}-frontend-from-prometheus-ingress"
  })
}

# ==============================================================================
# IAM Policy for S3 Config Access
# ==============================================================================

# IAM policy document for S3 config access
# Allows ECS tasks to read Prometheus config from S3
data "aws_iam_policy_document" "prometheus_s3_config_access" {
  statement {
    sid    = "AllowPrometheusConfigRead"
    effect = "Allow"

    actions = [
      "s3:GetObject",
      "s3:GetObjectVersion",
    ]

    resources = [
      "${aws_s3_bucket.prometheus_config.arn}/*",
    ]
  }

  statement {
    sid    = "AllowBucketList"
    effect = "Allow"

    actions = [
      "s3:ListBucket",
    ]

    resources = [
      aws_s3_bucket.prometheus_config.arn,
    ]
  }
}

# IAM policy for Prometheus task role
# Attach this to the Prometheus ECS task role in compute module
resource "aws_iam_policy" "prometheus_s3_config_access" {
  name_prefix = "${local.name_prefix}-prometheus-s3-config-"
  description = "Allow Prometheus ECS tasks to read configuration from S3"
  policy      = data.aws_iam_policy_document.prometheus_s3_config_access.json

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-prometheus-s3-config-policy"
    }
  )
}

# ==============================================================================
# CloudWatch Log Group for Prometheus
# ==============================================================================

# CloudWatch log group for Prometheus container logs
resource "aws_cloudwatch_log_group" "prometheus" {
  count = var.enable_prometheus_efs ? 1 : 0

  name              = "/ecs/${local.name_prefix}/prometheus"
  retention_in_days = var.log_retention_days

  tags = merge(
    local.common_tags,
    {
      Name        = "${local.name_prefix}-prometheus-logs"
      Application = "prometheus"
    }
  )
}

# CloudWatch log group for Grafana container logs
# Centralizes logs for troubleshooting dashboard loading or auth issues
resource "aws_cloudwatch_log_group" "grafana" {
  count = var.enable_grafana ? 1 : 0

  name              = "/ecs/${local.name_prefix}/grafana"
  retention_in_days = var.log_retention_days

  tags = merge(
    local.common_tags,
    {
      Name        = "${local.name_prefix}-grafana-logs"
      Application = "grafana"
    }
  )
}

# ==============================================================================
# IAM Roles for ECS Tasks
# ==============================================================================

# Task Execution Role - Allows ECS to pull images and write logs
# This role is used by the ECS service to manage the task lifecycle
data "aws_iam_policy_document" "ecs_task_execution_assume" {
  statement {
    effect = "Allow"

    principals {
      type        = "Service"
      identifiers = ["ecs-tasks.amazonaws.com"]
    }

    actions = ["sts:AssumeRole"]
  }
}

resource "aws_iam_role" "prometheus_task_execution" {
  count = var.enable_prometheus_efs ? 1 : 0

  name_prefix        = "${local.name_prefix}-prometheus-exec-"
  assume_role_policy = data.aws_iam_policy_document.ecs_task_execution_assume.json

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-prometheus-execution-role"
    }
  )
}

# Attach AWS-managed policy for ECS task execution (ECR, CloudWatch Logs)
resource "aws_iam_role_policy_attachment" "prometheus_task_execution" {
  count = var.enable_prometheus_efs ? 1 : 0

  role       = aws_iam_role.prometheus_task_execution[0].name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
}

# Grafana Task Execution Role
# Allows ECS agent to pull images, push logs to CloudWatch, and access secrets
resource "aws_iam_role" "grafana_task_execution" {
  count = var.enable_grafana ? 1 : 0

  name_prefix        = "${local.name_prefix}-grafana-exec-"
  assume_role_policy = data.aws_iam_policy_document.ecs_task_execution_assume.json

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-grafana-execution-role"
    }
  )
}

resource "aws_iam_role_policy_attachment" "grafana_task_execution" {
  count = var.enable_grafana ? 1 : 0

  role       = aws_iam_role.grafana_task_execution[0].name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
}

# Allow Grafana Execution Role to access Secrets Manager (for admin password)
# This permission is required for ECS to inject the secret as an environment variable
resource "aws_iam_policy" "grafana_secrets" {
  count = var.enable_grafana ? 1 : 0

  name_prefix = "${local.name_prefix}-grafana-secrets-"
  description = "Allow Grafana to access secrets"

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Action = [
          "secretsmanager:GetSecretValue"
        ]
        Resource = [
          aws_secretsmanager_secret.grafana_admin[0].arn
        ]
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "grafana_secrets" {
  count = var.enable_grafana ? 1 : 0

  role       = aws_iam_role.grafana_task_execution[0].name
  policy_arn = aws_iam_policy.grafana_secrets[0].arn
}

# Task Role - Allows Prometheus containers to access AWS services (S3 config)
# This role is used by the containers themselves during runtime
data "aws_iam_policy_document" "ecs_task_assume" {
  statement {
    effect = "Allow"

    principals {
      type        = "Service"
      identifiers = ["ecs-tasks.amazonaws.com"]
    }

    actions = ["sts:AssumeRole"]
  }
}

resource "aws_iam_role" "prometheus_task" {
  count = var.enable_prometheus_efs ? 1 : 0

  name_prefix        = "${local.name_prefix}-prometheus-task-"
  assume_role_policy = data.aws_iam_policy_document.ecs_task_assume.json

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-prometheus-task-role"
    }
  )
}

# Attach S3 config access policy to task role
resource "aws_iam_role_policy_attachment" "prometheus_s3_config" {
  count = var.enable_prometheus_efs ? 1 : 0

  role       = aws_iam_role.prometheus_task[0].name
  policy_arn = aws_iam_policy.prometheus_s3_config_access.arn
}

# Attach SSM policy for ECS Exec (when enabled)
resource "aws_iam_role_policy_attachment" "prometheus_ecs_exec" {
  count = var.enable_prometheus_efs && var.enable_ecs_exec ? 1 : 0

  role       = aws_iam_role.prometheus_task[0].name
  policy_arn = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
}

resource "aws_iam_role" "grafana_task" {
  count = var.enable_grafana ? 1 : 0

  name_prefix        = "${local.name_prefix}-grafana-task-"
  assume_role_policy = data.aws_iam_policy_document.ecs_task_assume.json

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-grafana-task-role"
    }
  )
}

# Attach SSM policy for ECS Exec debugging
resource "aws_iam_role_policy_attachment" "grafana_ecs_exec" {
  count = var.enable_grafana && var.enable_ecs_exec ? 1 : 0

  role       = aws_iam_role.grafana_task[0].name
  policy_arn = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
}

# ==============================================================================
# ECS Task Definitions
# ==============================================================================

# Prometheus Task Definition
resource "aws_ecs_task_definition" "prometheus" {
  count = var.enable_prometheus_efs ? 1 : 0

  family                   = "${local.name_prefix}-prometheus"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  cpu                      = var.prometheus_task_cpu
  memory                   = var.prometheus_task_memory
  execution_role_arn       = aws_iam_role.prometheus_task_execution[0].arn
  task_role_arn            = aws_iam_role.prometheus_task[0].arn

  # EFS volume for Prometheus data and config
  volume {
    name = "prometheus-data"

    efs_volume_configuration {
      file_system_id     = aws_efs_file_system.prometheus[0].id
      transit_encryption = "ENABLED"
      authorization_config {
        iam = "DISABLED"
      }
    }
  }

  container_definitions = jsonencode([
    # Init container: Sync S3 config to EFS
    {
      name      = "init-config-sync"
      image     = "amazon/aws-cli:2.17.9"
      essential = false

      # Create data directory, set ownership for Prometheus user (65534), and sync config from S3 to EFS
      entryPoint = ["/bin/sh", "-c"]
      command = [
        join(" && ", [
          "mkdir -p /prometheus/data",
          "chown -R ${local.prometheus_user_id}:${local.prometheus_user_id} /prometheus",
          "aws s3 cp s3://${aws_s3_bucket.prometheus_config.id}/${var.prometheus_config_s3_key} /prometheus/prometheus.yml"
        ])
      ]

      mountPoints = [
        {
          sourceVolume  = "prometheus-data"
          containerPath = "/prometheus"
          readOnly      = false
        }
      ]

      logConfiguration = {
        logDriver = "awslogs"
        options = {
          "awslogs-group"         = aws_cloudwatch_log_group.prometheus[0].name
          "awslogs-region"        = var.aws_region
          "awslogs-stream-prefix" = "init"
        }
      }

      # Note: Init container runs as root (default) to have write permissions to EFS
      # Prometheus container runs as UID 65534 for security
    },
    # Main Prometheus container
    {
      name      = "prometheus"
      image     = var.prometheus_image
      essential = true

      portMappings = [
        {
          containerPort = local.prometheus_port
          protocol      = "tcp"
        }
      ]

      mountPoints = [
        {
          sourceVolume  = "prometheus-data"
          containerPath = "/prometheus"
          readOnly      = false
        }
      ]

      command = [
        "--config.file=/prometheus/prometheus.yml",
        "--storage.tsdb.path=/prometheus/data",
        "--storage.tsdb.retention.time=${var.prometheus_retention_time}",
        "--web.console.libraries=/usr/share/prometheus/console_libraries",
        "--web.console.templates=/usr/share/prometheus/consoles",
        "--web.enable-lifecycle"
      ]

      healthCheck = {
        command     = ["CMD-SHELL", "promtool check config /prometheus/prometheus.yml && nc -z 127.0.0.1 ${local.prometheus_port} || exit 1"]
        interval    = 30
        timeout     = 5
        retries     = 3
        startPeriod = 60
      }

      logConfiguration = {
        logDriver = "awslogs"
        options = {
          "awslogs-group"         = aws_cloudwatch_log_group.prometheus[0].name
          "awslogs-region"        = var.aws_region
          "awslogs-stream-prefix" = "prometheus"
        }
      }

      # Run as non-root user (UID 65534 = nobody, standard Prometheus user)
      user = local.prometheus_user_id

      # Container dependencies - wait for init container
      dependsOn = [
        {
          containerName = "init-config-sync"
          condition     = "SUCCESS"
        }
      ]
    }
  ])

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-prometheus-task"
    }
  )
}

# Grafana Task Definition
# Includes two containers:
# 1. init-chown: Sidecar to fix EFS permission issues (sets ownership to uid 472)
# 2. grafana: Main application container
resource "aws_ecs_task_definition" "grafana" {
  count = var.enable_grafana ? 1 : 0

  family                   = "${local.name_prefix}-grafana"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  cpu                      = var.grafana_task_cpu
  memory                   = var.grafana_task_memory
  execution_role_arn       = aws_iam_role.grafana_task_execution[0].arn
  task_role_arn            = aws_iam_role.grafana_task[0].arn

  # Mount EFS volume for persistent data storage
  volume {
    name = "grafana-data"

    efs_volume_configuration {
      file_system_id     = aws_efs_file_system.grafana[0].id
      transit_encryption = "ENABLED"
      authorization_config {
        iam = "DISABLED"
      }
    }
  }

  container_definitions = jsonencode([
    {
      name      = "init-chown"
      image     = "busybox:1.36.1" # Lightweight image to change ownership
      essential = false
      # Fix ownership of the mounted EFS volume to match Grafana user (uid 472)
      # EFS mounts as root by default, which Grafana cannot write to
      command = ["chown", "-R", "${local.grafana_user_id}:${local.grafana_user_id}", "/var/lib/grafana"]
      mountPoints = [
        {
          sourceVolume  = "grafana-data"
          containerPath = "/var/lib/grafana"
          readOnly      = false
        }
      ]
      logConfiguration = {
        logDriver = "awslogs"
        options = {
          "awslogs-group"         = aws_cloudwatch_log_group.grafana[0].name
          "awslogs-region"        = var.aws_region
          "awslogs-stream-prefix" = "init"
        }
      }
    },
    {
      name      = "grafana"
      image     = var.grafana_image
      essential = true
      portMappings = [
        {
          containerPort = local.grafana_port
          protocol      = "tcp"
        }
      ]
      mountPoints = [
        {
          sourceVolume  = "grafana-data"
          containerPath = "/var/lib/grafana"
          readOnly      = false
        }
      ]
      environment = [
        {
          name  = "GF_SERVER_ROOT_URL"
          value = var.grafana_domain_name != "" ? "https://${var.grafana_domain_name}/" : "%(protocol)s://%(domain)s:%(http_port)s/"
        },
        {
          name  = "GF_SERVER_DOMAIN"
          value = var.grafana_domain_name != "" ? var.grafana_domain_name : "localhost"
        }
      ]
      secrets = [
        {
          name      = "GF_SECURITY_ADMIN_PASSWORD"
          valueFrom = aws_secretsmanager_secret.grafana_admin[0].arn
        }
      ]
      logConfiguration = {
        logDriver = "awslogs"
        options = {
          "awslogs-group"         = aws_cloudwatch_log_group.grafana[0].name
          "awslogs-region"        = var.aws_region
          "awslogs-stream-prefix" = "grafana"
        }
      }
      dependsOn = [
        {
          containerName = "init-chown"
          condition     = "SUCCESS"
        }
      ]
    }
  ])

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-grafana-task"
    }
  )
}

# ==============================================================================
# Load Balancer Configuration (ALB)
# ==============================================================================

# Grafana Target Group
resource "aws_lb_target_group" "grafana" {
  count = var.enable_grafana && var.alb_listener_arn != null ? 1 : 0

  name        = "${local.name_prefix}-grafana-tg"
  port        = local.grafana_port
  protocol    = "HTTP"
  vpc_id      = var.vpc_id
  target_type = "ip"

  health_check {
    enabled             = true
    healthy_threshold   = 2
    unhealthy_threshold = 2
    timeout             = 5
    interval            = 30
    path                = "/api/health" # Grafana health endpoint
    protocol            = "HTTP"
    matcher             = "200"
  }

  deregistration_delay = 30

  tags = merge(
    local.common_tags,
    {
      Name        = "${local.name_prefix}-grafana-tg"
      Application = "grafana"
    }
  )
}

# Grafana Listener Rule
# Routes traffic for grafana.domain.com to the Grafana target group
resource "aws_lb_listener_rule" "grafana" {
  count = var.enable_grafana && var.alb_listener_arn != null && var.grafana_domain_name != "" ? 1 : 0

  listener_arn = var.alb_listener_arn
  priority     = 90 # Higher priority than backend (100)

  action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.grafana[0].arn
  }

  condition {
    host_header {
      values = [var.grafana_domain_name]
    }
  }

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-grafana-rule"
    }
  )
}

# ==============================================================================
# ECS Services
# ==============================================================================

# Prometheus ECS service with service discovery
resource "aws_ecs_service" "prometheus" {
  count = var.enable_prometheus_efs ? 1 : 0

  name            = "${local.name_prefix}-prometheus"
  cluster         = var.ecs_cluster_id
  task_definition = aws_ecs_task_definition.prometheus[0].arn
  desired_count   = var.prometheus_desired_count
  launch_type     = "FARGATE"

  network_configuration {
    subnets          = var.private_app_subnet_ids
    security_groups  = [var.prometheus_security_group_id]
    assign_public_ip = false
  }

  service_registries {
    registry_arn   = var.prometheus_service_registry_arn
    container_name = "prometheus"
    container_port = local.prometheus_port
  }

  health_check_grace_period_seconds = 60

  # Deployment configuration for Prometheus with EFS
  # Uses "recreate" strategy to avoid EFS database locking conflicts:
  # - Prometheus TSDB requires exclusive file lock on EFS volume
  # - Only one task can hold the lock at a time
  # - Setting deployment_minimum_healthy_percent = 0 allows old task to stop FIRST
  # - This releases the EFS lock before new task starts
  # - Trade-off: 60-90 seconds downtime during deployments (acceptable for dev)
  # - Alternative: Rolling updates cause deadlock (new task can't get lock, old won't stop)
  deployment_minimum_healthy_percent = 0 # Allow old task to stop first (releases EFS lock)

  # AWS ECS enables AZ rebalancing by default for services deployed across multiple AZs.
  # When AZ rebalancing is enabled, maximum_percent must be > 100 to allow temporary
  # over-provisioning during rebalancing operations. Attempting to set this to 100
  # results in: "InvalidParameterException: Availability Zone Rebalancing does not
  # support maximumPercent <= 100". Using the AWS default value of 200.
  deployment_maximum_percent = 200

  deployment_circuit_breaker {
    enable   = true # Automatically rollback failed deployments
    rollback = true
  }

  # Enable ECS Exec for debugging (optional)
  enable_execute_command = var.enable_ecs_exec

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-prometheus-service"
    }
  )

  # Wait for EFS mount targets to be available
  depends_on = [
    aws_efs_mount_target.prometheus
  ]
}

# Grafana Service
# Manages the running ECS tasks for Grafana
resource "aws_ecs_service" "grafana" {
  count = var.enable_grafana ? 1 : 0

  name            = "${local.name_prefix}-grafana"
  cluster         = var.ecs_cluster_id
  task_definition = aws_ecs_task_definition.grafana[0].arn
  desired_count   = var.grafana_desired_count
  launch_type     = "FARGATE"

  network_configuration {
    subnets          = var.private_app_subnet_ids
    security_groups  = [local.grafana_sg_id]
    assign_public_ip = false
  }

  # Attach to ALB if listener ARN is provided
  dynamic "load_balancer" {
    for_each = var.alb_listener_arn != null ? [1] : []
    content {
      target_group_arn = aws_lb_target_group.grafana[0].arn
      container_name   = "grafana"
      container_port   = local.grafana_port
    }
  }

  # Register with AWS Cloud Map for service discovery
  service_registries {
    registry_arn   = var.grafana_service_registry_arn
    container_name = "grafana"
    container_port = local.grafana_port
  }

  # Deployment configuration for EFS-backed service
  # Uses "recreate" strategy (minimum_healthy_percent = 0) because SQLite on EFS
  # requires exclusive file locking. A rolling update (min=100, max=200) would
  # cause a new task to start while the old one still holds the lock, leading to database errors.
  health_check_grace_period_seconds  = 60
  deployment_minimum_healthy_percent = 0 # Allows old task to stop before new one starts
  deployment_maximum_percent         = 200

  deployment_circuit_breaker {
    enable   = true
    rollback = true
  }

  enable_execute_command = var.enable_ecs_exec

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-grafana-service"
    }
  )

  depends_on = [
    aws_efs_mount_target.grafana
  ]
}
