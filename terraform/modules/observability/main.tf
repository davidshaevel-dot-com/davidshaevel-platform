# ==============================================================================
# Observability Module - Main Configuration
# ==============================================================================
#
# This module provisions infrastructure for the observability stack:
# - S3 bucket for Prometheus configuration storage
# - EFS file system for Prometheus TSDB data persistence
# - EFS mount targets for high availability across multiple AZs
# - Security groups for EFS NFS access
# - IAM policies for S3 and EFS access from ECS tasks
#
# Phase 3 of TT-25: EFS file systems and supporting infrastructure
#
# Architecture:
# 1. Prometheus config rendered by Terraform → S3 bucket
# 2. ECS init container syncs S3 → EFS (one-time per task start)
# 3. Prometheus container reads config from EFS, writes data to EFS
# 4. EFS provides persistent storage across task restarts

locals {
  name_prefix        = "${var.environment}-${var.project_name}"
  prometheus_port    = 9090
  nfs_port           = 2049    # Standard NFS/EFS mount port
  prometheus_user_id = "65534" # UID for 'nobody' user - standard Prometheus non-root user

  common_tags = merge(
    var.tags,
    {
      Module      = "observability"
      Environment = var.environment
      Project     = var.project_name
      ManagedBy   = "Terraform"
    }
  )
}

# ==============================================================================
# S3 Bucket for Prometheus Configuration
# ==============================================================================

# S3 bucket to store rendered Prometheus configuration files
# Config is generated by Terraform from prometheus.yml.tpl template
# and synced to EFS by init container on task startup
resource "aws_s3_bucket" "prometheus_config" {
  bucket = "${local.name_prefix}-prometheus-config"

  tags = merge(
    local.common_tags,
    {
      Name    = "${local.name_prefix}-prometheus-config"
      Purpose = "Prometheus configuration storage"
    }
  )
}

# Enable versioning to track config changes over time
resource "aws_s3_bucket_versioning" "prometheus_config" {
  count  = var.enable_config_bucket_versioning ? 1 : 0
  bucket = aws_s3_bucket.prometheus_config.id

  versioning_configuration {
    status = "Enabled"
  }
}

# Enable encryption at rest with AWS-managed keys
resource "aws_s3_bucket_server_side_encryption_configuration" "prometheus_config" {
  bucket = aws_s3_bucket.prometheus_config.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# Block all public access to config bucket
resource "aws_s3_bucket_public_access_block" "prometheus_config" {
  bucket = aws_s3_bucket.prometheus_config.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# Lifecycle policy to expire old config versions
resource "aws_s3_bucket_lifecycle_configuration" "prometheus_config" {
  count  = var.config_bucket_lifecycle_days > 0 ? 1 : 0
  bucket = aws_s3_bucket.prometheus_config.id

  rule {
    id     = "expire-old-versions"
    status = "Enabled"

    noncurrent_version_expiration {
      noncurrent_days = var.config_bucket_lifecycle_days
    }
  }
}

# ==============================================================================
# EFS File System for Prometheus Data
# ==============================================================================

# EFS file system for Prometheus TSDB data persistence
# Stores metrics data across ECS task restarts
# Multi-AZ for high availability
resource "aws_efs_file_system" "prometheus" {
  count = var.enable_prometheus_efs ? 1 : 0

  # Performance configuration
  performance_mode = var.prometheus_efs_performance_mode
  throughput_mode  = var.prometheus_efs_throughput_mode

  # Encryption at rest with AWS-managed KMS key
  encrypted = var.enable_efs_encryption

  # EFS Lifecycle policies:
  # 1. Transition files to Infrequent Access (IA) storage after a configured
  #    number of days (`var.efs_transition_to_ia_days`) to reduce storage costs.
  # 2. Transition files back to Standard storage from IA on the first access
  #    to ensure performance for active data.
  lifecycle_policy {
    transition_to_ia = "AFTER_${var.efs_transition_to_ia_days}_DAYS"
  }

  lifecycle_policy {
    transition_to_primary_storage_class = "AFTER_1_ACCESS"
  }

  tags = merge(
    local.common_tags,
    {
      Name    = "${local.name_prefix}-prometheus-data"
      Purpose = "Prometheus TSDB data persistence"
    }
  )
}

# ==============================================================================
# EFS Mount Targets
# ==============================================================================

# Create EFS mount target in each private app subnet for multi-AZ availability
# Allows ECS tasks in any AZ to access the file system
resource "aws_efs_mount_target" "prometheus" {
  count = var.enable_prometheus_efs ? length(var.private_app_subnet_ids) : 0

  file_system_id  = aws_efs_file_system.prometheus[0].id
  subnet_id       = var.private_app_subnet_ids[count.index]
  security_groups = [aws_security_group.efs[0].id]
}

# ==============================================================================
# EFS Security Group
# ==============================================================================

# Security group for EFS mount targets
# Allows NFS traffic (port 2049) from Prometheus ECS tasks
resource "aws_security_group" "efs" {
  count = var.enable_prometheus_efs ? 1 : 0

  name_prefix = "${local.name_prefix}-efs-"
  description = "Security group for Prometheus EFS mount targets"
  vpc_id      = var.vpc_id

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-efs-sg"
    }
  )

  lifecycle {
    create_before_destroy = true
  }
}

# Ingress rule: Allow NFS (port 2049) from Prometheus security group
# Security groups are stateful - this ingress rule automatically allows return traffic
# No explicit egress rule needed for EFS mount targets (passive endpoints)
resource "aws_vpc_security_group_ingress_rule" "efs_nfs_from_prometheus" {
  count = var.enable_prometheus_efs ? 1 : 0

  security_group_id            = aws_security_group.efs[0].id
  description                  = "Allow NFS from Prometheus ECS tasks"
  referenced_security_group_id = var.prometheus_security_group_id
  from_port                    = local.nfs_port
  to_port                      = local.nfs_port
  ip_protocol                  = "tcp"

  tags = merge(
    local.common_tags,
    {
      Name = "efs-nfs-from-prometheus"
    }
  )
}

# Egress rule: Allow Prometheus to connect to EFS on NFS port
# Required for Fargate tasks to mount EFS volumes
resource "aws_vpc_security_group_egress_rule" "prometheus_to_efs" {
  count = var.enable_prometheus_efs ? 1 : 0

  security_group_id            = var.prometheus_security_group_id
  description                  = "Allow NFS to EFS mount targets"
  referenced_security_group_id = aws_security_group.efs[0].id
  from_port                    = local.nfs_port
  to_port                      = local.nfs_port
  ip_protocol                  = "tcp"

  tags = merge(
    local.common_tags,
    {
      Name = "prometheus-to-efs-nfs"
    }
  )
}

# ==============================================================================
# IAM Policy for S3 Config Access
# ==============================================================================

# IAM policy document for S3 config access
# Allows ECS tasks to read Prometheus config from S3
data "aws_iam_policy_document" "prometheus_s3_config_access" {
  statement {
    sid    = "AllowPrometheusConfigRead"
    effect = "Allow"

    actions = [
      "s3:GetObject",
      "s3:GetObjectVersion",
    ]

    resources = [
      "${aws_s3_bucket.prometheus_config.arn}/*",
    ]
  }

  statement {
    sid    = "AllowBucketList"
    effect = "Allow"

    actions = [
      "s3:ListBucket",
    ]

    resources = [
      aws_s3_bucket.prometheus_config.arn,
    ]
  }
}

# IAM policy for Prometheus task role
# Attach this to the Prometheus ECS task role in compute module
resource "aws_iam_policy" "prometheus_s3_config_access" {
  name_prefix = "${local.name_prefix}-prometheus-s3-config-"
  description = "Allow Prometheus ECS tasks to read configuration from S3"
  policy      = data.aws_iam_policy_document.prometheus_s3_config_access.json

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-prometheus-s3-config-policy"
    }
  )
}

# ==============================================================================
# CloudWatch Log Group for Prometheus
# ==============================================================================

# CloudWatch log group for Prometheus container logs
resource "aws_cloudwatch_log_group" "prometheus" {
  count = var.enable_prometheus_efs ? 1 : 0

  name              = "/ecs/${local.name_prefix}/prometheus"
  retention_in_days = var.log_retention_days

  tags = merge(
    local.common_tags,
    {
      Name        = "${local.name_prefix}-prometheus-logs"
      Application = "prometheus"
    }
  )
}

# ==============================================================================
# IAM Roles for Prometheus ECS Task
# ==============================================================================

# Task Execution Role - Allows ECS to pull images and write logs
# This role is used by the ECS service to manage the task lifecycle
data "aws_iam_policy_document" "prometheus_task_execution_assume" {
  statement {
    effect = "Allow"

    principals {
      type        = "Service"
      identifiers = ["ecs-tasks.amazonaws.com"]
    }

    actions = ["sts:AssumeRole"]
  }
}

resource "aws_iam_role" "prometheus_task_execution" {
  count = var.enable_prometheus_efs ? 1 : 0

  name_prefix        = "${local.name_prefix}-prometheus-exec-"
  assume_role_policy = data.aws_iam_policy_document.prometheus_task_execution_assume.json

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-prometheus-execution-role"
    }
  )
}

# Attach AWS-managed policy for ECS task execution (ECR, CloudWatch Logs)
resource "aws_iam_role_policy_attachment" "prometheus_task_execution" {
  count = var.enable_prometheus_efs ? 1 : 0

  role       = aws_iam_role.prometheus_task_execution[0].name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
}

# Task Role - Allows Prometheus containers to access AWS services (S3 config)
# This role is used by the containers themselves during runtime
data "aws_iam_policy_document" "prometheus_task_assume" {
  statement {
    effect = "Allow"

    principals {
      type        = "Service"
      identifiers = ["ecs-tasks.amazonaws.com"]
    }

    actions = ["sts:AssumeRole"]
  }
}

resource "aws_iam_role" "prometheus_task" {
  count = var.enable_prometheus_efs ? 1 : 0

  name_prefix        = "${local.name_prefix}-prometheus-task-"
  assume_role_policy = data.aws_iam_policy_document.prometheus_task_assume.json

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-prometheus-task-role"
    }
  )
}

# Attach S3 config access policy to task role
resource "aws_iam_role_policy_attachment" "prometheus_s3_config" {
  count = var.enable_prometheus_efs ? 1 : 0

  role       = aws_iam_role.prometheus_task[0].name
  policy_arn = aws_iam_policy.prometheus_s3_config_access.arn
}

# Attach SSM policy for ECS Exec (when enabled)
resource "aws_iam_role_policy_attachment" "prometheus_ecs_exec" {
  count = var.enable_prometheus_efs && var.enable_ecs_exec ? 1 : 0

  role       = aws_iam_role.prometheus_task[0].name
  policy_arn = "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
}

# ==============================================================================
# ECS Task Definition for Prometheus
# ==============================================================================

# Prometheus task definition with init container pattern:
# 1. Init container syncs S3 config → EFS (runs once at startup)
# 2. Prometheus container reads config from EFS, writes data to EFS
resource "aws_ecs_task_definition" "prometheus" {
  count = var.enable_prometheus_efs ? 1 : 0

  family                   = "${local.name_prefix}-prometheus"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  cpu                      = var.prometheus_task_cpu
  memory                   = var.prometheus_task_memory
  execution_role_arn       = aws_iam_role.prometheus_task_execution[0].arn
  task_role_arn            = aws_iam_role.prometheus_task[0].arn

  # EFS volume for Prometheus data and config
  volume {
    name = "prometheus-data"

    efs_volume_configuration {
      file_system_id     = aws_efs_file_system.prometheus[0].id
      transit_encryption = "ENABLED"
      authorization_config {
        iam = "DISABLED"
      }
    }
  }

  container_definitions = jsonencode([
    # Init container: Sync S3 config to EFS
    {
      name      = "init-config-sync"
      image     = "amazon/aws-cli:2.17.9"
      essential = false

      # Create data directory, set ownership for Prometheus user (65534), and sync config from S3 to EFS
      entryPoint = ["/bin/sh", "-c"]
      command = [
        join(" && ", [
          "mkdir -p /prometheus/data",
          "chown -R ${local.prometheus_user_id}:${local.prometheus_user_id} /prometheus",
          "aws s3 cp s3://${aws_s3_bucket.prometheus_config.id}/${var.prometheus_config_s3_key} /prometheus/prometheus.yml"
        ])
      ]

      mountPoints = [
        {
          sourceVolume  = "prometheus-data"
          containerPath = "/prometheus"
          readOnly      = false
        }
      ]

      logConfiguration = {
        logDriver = "awslogs"
        options = {
          "awslogs-group"         = aws_cloudwatch_log_group.prometheus[0].name
          "awslogs-region"        = var.aws_region
          "awslogs-stream-prefix" = "init"
        }
      }

      # Note: Init container runs as root (default) to have write permissions to EFS
      # Prometheus container runs as UID 65534 for security
    },
    # Main Prometheus container
    {
      name      = "prometheus"
      image     = var.prometheus_image
      essential = true

      portMappings = [
        {
          containerPort = local.prometheus_port
          protocol      = "tcp"
        }
      ]

      mountPoints = [
        {
          sourceVolume  = "prometheus-data"
          containerPath = "/prometheus"
          readOnly      = false
        }
      ]

      command = [
        "--config.file=/prometheus/prometheus.yml",
        "--storage.tsdb.path=/prometheus/data",
        "--storage.tsdb.retention.time=${var.prometheus_retention_time}",
        "--web.console.libraries=/usr/share/prometheus/console_libraries",
        "--web.console.templates=/usr/share/prometheus/consoles",
        "--web.enable-lifecycle"
      ]

      healthCheck = {
        command     = ["CMD-SHELL", "promtool check config /prometheus/prometheus.yml && nc -z 127.0.0.1 ${local.prometheus_port} || exit 1"]
        interval    = 30
        timeout     = 5
        retries     = 3
        startPeriod = 60
      }

      logConfiguration = {
        logDriver = "awslogs"
        options = {
          "awslogs-group"         = aws_cloudwatch_log_group.prometheus[0].name
          "awslogs-region"        = var.aws_region
          "awslogs-stream-prefix" = "prometheus"
        }
      }

      # Run as non-root user (UID 65534 = nobody, standard Prometheus user)
      user = local.prometheus_user_id

      # Container dependencies - wait for init container
      dependsOn = [
        {
          containerName = "init-config-sync"
          condition     = "SUCCESS"
        }
      ]
    }
  ])

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-prometheus-task"
    }
  )
}

# ==============================================================================
# ECS Service for Prometheus
# ==============================================================================

# Prometheus ECS service with service discovery
resource "aws_ecs_service" "prometheus" {
  count = var.enable_prometheus_efs ? 1 : 0

  name            = "${local.name_prefix}-prometheus"
  cluster         = var.ecs_cluster_id
  task_definition = aws_ecs_task_definition.prometheus[0].arn
  desired_count   = var.prometheus_desired_count
  launch_type     = "FARGATE"

  network_configuration {
    subnets          = var.private_app_subnet_ids
    security_groups  = [var.prometheus_security_group_id]
    assign_public_ip = false
  }

  # Service discovery registration
  service_registries {
    registry_arn   = var.prometheus_service_registry_arn
    container_name = "prometheus"
    container_port = local.prometheus_port
  }

  # Health check grace period for container startup
  health_check_grace_period_seconds = 60

  # Deployment configuration for Prometheus with EFS
  # Uses "recreate" strategy to avoid EFS database locking conflicts:
  # - Prometheus TSDB requires exclusive file lock on EFS volume
  # - Only one task can hold the lock at a time
  # - Setting deployment_minimum_healthy_percent = 0 allows old task to stop FIRST
  # - This releases the EFS lock before new task starts
  # - Trade-off: 60-90 seconds downtime during deployments (acceptable for dev)
  # - Alternative: Rolling updates cause deadlock (new task can't get lock, old won't stop)
  # - maximum_percent = 200 required by AWS AZ rebalancing (can't be <= 100)
  deployment_minimum_healthy_percent = 0    # Allow old task to stop first (releases EFS lock)
  deployment_maximum_percent         = 200  # AWS AZ rebalancing requires > 100

  deployment_circuit_breaker {
    enable   = true   # Automatically rollback failed deployments
    rollback = true
  }

  # Enable ECS Exec for debugging (optional)
  enable_execute_command = var.enable_ecs_exec

  tags = merge(
    local.common_tags,
    {
      Name = "${local.name_prefix}-prometheus-service"
    }
  )

  # Wait for EFS mount targets to be available
  depends_on = [
    aws_efs_mount_target.prometheus
  ]
}
